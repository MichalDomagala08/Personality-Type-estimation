{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Michał\\Downloads\\mbti-type\\mbti_1.csv\",sep = \",\", engine = \"python\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "cnt_srs = df['type'].value_counts()\n",
    "viridis = cm.get_cmap('plasma', 12)\n",
    "colors = viridis(np.flip(np.linspace(0, 1, 16)))\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8,palette=colors)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Types', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "cnt_srs = df['type'].value_counts()\n",
    "viridis = cm.get_cmap('plasma', 12)\n",
    "colors = viridis(np.flip(np.linspace(0, 1, 16)))\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8,palette=colors)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Types', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_per_post():\n",
    "\n",
    "    df['words_per_post'] = 0\n",
    "    for i in range(len(df.index)):\n",
    "        df['words_per_post'].loc[i] = len(df[\"posts\"].loc[i].split())/50\n",
    "        #print(len(df[\"posts\"].loc[i].split())/50)\n",
    "\n",
    "def Average_frase_per_person(frase):\n",
    "    df[\"{} per Post\".format(frase)] = 0\n",
    "    for i in range(len(df.index)):\n",
    "        df[\"{} per Post\".format(frase)].loc[i]  = df[\"posts\"].loc[i].count(frase)/50\n",
    "   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>15.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>26.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>18.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>34.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>27.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  words_per_post\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...           23.40\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...           16.72\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...           19.34\n",
       "...    ...                                                ...             ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           15.92\n",
       "8671  ENFP  'So...if this thread already exists someplace ...           26.18\n",
       "8672  INTP  'So many questions when i do these things.  I ...           18.96\n",
       "8673  INFP  'I am very conflicted right now when it comes ...           34.10\n",
       "8674  INFP  'It has been too long since I have been on per...           27.22\n",
       "\n",
       "[8675 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cecha 1: Ile słów na post używa dana osoba?\n",
    "\n",
    "words_per_post()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "      <th>... per Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>27.22</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  words_per_post  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...           23.40   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...           16.72   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...           19.34   \n",
       "...    ...                                                ...             ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           15.92   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...           26.18   \n",
       "8672  INTP  'So many questions when i do these things.  I ...           18.96   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...           34.10   \n",
       "8674  INFP  'It has been too long since I have been on per...           27.22   \n",
       "\n",
       "      ... per Post  \n",
       "0             0.30  \n",
       "1             0.38  \n",
       "2             0.26  \n",
       "3             0.52  \n",
       "4             0.42  \n",
       "...            ...  \n",
       "8670          0.14  \n",
       "8671          0.82  \n",
       "8672          0.38  \n",
       "8673          0.94  \n",
       "8674          0.48  \n",
       "\n",
       "[8675 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cecha 2: Ile średnio wielokropków na post używa dana osoba?\n",
    "\n",
    "Average_frase_per_person('...')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "      <th>... per Post</th>\n",
       "      <th>http per Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>27.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  words_per_post  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...           23.40   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...           16.72   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...           19.34   \n",
       "...    ...                                                ...             ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           15.92   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...           26.18   \n",
       "8672  INTP  'So many questions when i do these things.  I ...           18.96   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...           34.10   \n",
       "8674  INFP  'It has been too long since I have been on per...           27.22   \n",
       "\n",
       "      ... per Post  http per Post  \n",
       "0             0.30           0.48  \n",
       "1             0.38           0.20  \n",
       "2             0.26           0.10  \n",
       "3             0.52           0.04  \n",
       "4             0.42           0.12  \n",
       "...            ...            ...  \n",
       "8670          0.14           0.14  \n",
       "8671          0.82           0.04  \n",
       "8672          0.38           0.04  \n",
       "8673          0.94           0.00  \n",
       "8674          0.48           0.06  \n",
       "\n",
       "[8675 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Cecha 3: Ile średnio linków na post używa dana osoba?\n",
    "Average_frase_per_person('http')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "      <th>... per Post</th>\n",
       "      <th>http per Post</th>\n",
       "      <th>music per Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>27.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  words_per_post  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...           23.40   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...           16.72   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...           19.34   \n",
       "...    ...                                                ...             ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           15.92   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...           26.18   \n",
       "8672  INTP  'So many questions when i do these things.  I ...           18.96   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...           34.10   \n",
       "8674  INFP  'It has been too long since I have been on per...           27.22   \n",
       "\n",
       "      ... per Post  http per Post  music per Post  \n",
       "0             0.30           0.48            0.02  \n",
       "1             0.38           0.20            0.00  \n",
       "2             0.26           0.10            0.00  \n",
       "3             0.52           0.04            0.02  \n",
       "4             0.42           0.12            0.02  \n",
       "...            ...            ...             ...  \n",
       "8670          0.14           0.14            0.00  \n",
       "8671          0.82           0.04            0.00  \n",
       "8672          0.38           0.04            0.00  \n",
       "8673          0.94           0.00            0.00  \n",
       "8674          0.48           0.06            0.00  \n",
       "\n",
       "[8675 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cecha 4: Ile średnio frazy 'Muzyka' na post używa dana osoba?\n",
    "\n",
    "Average_frase_per_person('music')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "      <th>... per Post</th>\n",
       "      <th>http per Post</th>\n",
       "      <th>music per Post</th>\n",
       "      <th>jpg per Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>27.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  words_per_post  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...           23.40   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...           16.72   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...           19.34   \n",
       "...    ...                                                ...             ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           15.92   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...           26.18   \n",
       "8672  INTP  'So many questions when i do these things.  I ...           18.96   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...           34.10   \n",
       "8674  INFP  'It has been too long since I have been on per...           27.22   \n",
       "\n",
       "      ... per Post  http per Post  music per Post  jpg per Post  \n",
       "0             0.30           0.48            0.02          0.12  \n",
       "1             0.38           0.20            0.00          0.02  \n",
       "2             0.26           0.10            0.00          0.00  \n",
       "3             0.52           0.04            0.02          0.00  \n",
       "4             0.42           0.12            0.02          0.04  \n",
       "...            ...            ...             ...           ...  \n",
       "8670          0.14           0.14            0.00          0.02  \n",
       "8671          0.82           0.04            0.00          0.00  \n",
       "8672          0.38           0.04            0.00          0.00  \n",
       "8673          0.94           0.00            0.00          0.00  \n",
       "8674          0.48           0.06            0.00          0.00  \n",
       "\n",
       "[8675 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cecha 5: Ile średnio obrazków na post używa dana osoba?\n",
    "\n",
    "Average_frase_per_person('jpg')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "      <th>... per Post</th>\n",
       "      <th>http per Post</th>\n",
       "      <th>music per Post</th>\n",
       "      <th>jpg per Post</th>\n",
       "      <th>I per Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>34.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>27.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  words_per_post  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...           23.40   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...           16.72   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...           19.34   \n",
       "...    ...                                                ...             ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           15.92   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...           26.18   \n",
       "8672  INTP  'So many questions when i do these things.  I ...           18.96   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...           34.10   \n",
       "8674  INFP  'It has been too long since I have been on per...           27.22   \n",
       "\n",
       "      ... per Post  http per Post  music per Post  jpg per Post  I per Post  \n",
       "0             0.30           0.48            0.02          0.12        0.46  \n",
       "1             0.38           0.20            0.00          0.02        2.02  \n",
       "2             0.26           0.10            0.00          0.00        0.98  \n",
       "3             0.52           0.04            0.02          0.00        1.74  \n",
       "4             0.42           0.12            0.02          0.04        0.92  \n",
       "...            ...            ...             ...           ...         ...  \n",
       "8670          0.14           0.14            0.00          0.02        1.02  \n",
       "8671          0.82           0.04            0.00          0.00        2.40  \n",
       "8672          0.38           0.04            0.00          0.00        0.98  \n",
       "8673          0.94           0.00            0.00          0.00        3.22  \n",
       "8674          0.48           0.06            0.00          0.00        2.52  \n",
       "\n",
       "[8675 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cecha 6: Ile średnio SŁowa 'I' na post używa dana osoba?\n",
    "#Wzięte z Analizy częstości występowania\n",
    "\n",
    "Average_frase_per_person('I')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(values, xlabel, ylabel, xticklabels, yticklabels, cmap=None,\n",
    "            vmin=None, vmax=None, ax=None, fmt=\"%0.2f\"):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    # plot the mean cross-validation scores\n",
    "    img = ax.pcolor(values, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    img.update_scalarmappable()\n",
    "    ax.set_size()\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(np.arange(len(xticklabels)) + .5)\n",
    "    ax.set_yticks(np.arange(len(yticklabels)) + .5)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    for p, color, value in zip(img.get_paths(), img.get_facecolors(),\n",
    "                               img.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.mean(color[:3]) > 0.5:\n",
    "            c = 'k'\n",
    "        else:\n",
    "            c = 'w'\n",
    "        ax.text(x, y, fmt % value, color=c, ha=\"center\", va=\"center\")\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid_1 --> Zwyczajna absolutnie klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 6)\n",
      "(8675,)\n"
     ]
    }
   ],
   "source": [
    "XX = df.drop(['type','posts'], axis=1).values\n",
    "yy = df['type'].values\n",
    "\n",
    "print(XX.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Specs       Score\n",
      "0  words_per_post  219.272107\n",
      "5      I per Post   54.593654\n",
      "1    ... per Post   22.173564\n",
      "2   http per Post   13.328238\n",
      "3  music per Post    6.382853\n",
      "4    jpg per Post    1.907333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=6)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(df.drop(['type','posts'], axis=1).columns)\n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(6,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1 = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2 = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3 = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "print(grid_1.best_params_)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "print(grid_2.best_params_)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "print(grid_3.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models = []\n",
    "models.append(('SVM rbf', grid_1.best_estimator_))\n",
    "models.append(('LogReg', grid_2.best_estimator_))\n",
    "models.append(('RND', grid_3.best_estimator_))\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "XX = df.drop(['type','posts','clean_posts','I-E','N-S','T-F','J-P'], axis=1).values\n",
    "yy = df['type'].values\n",
    "\n",
    "print(XX.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n",
    "\n",
    "nm1 = NearMiss(version=1)\n",
    "sm = SMOTE()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "\n",
    "#print(y_train_res)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid2 --> Resampling normalnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1_res_normal = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2_res_normal = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3_res_normal = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1_res_normal.fit(X_train_res, y_train_res)\n",
    "print(grid_1_res_normal.best_params_)\n",
    "\n",
    "grid_2_res_normal.fit(X_train_res, y_train_res)\n",
    "print(grid_2_res_normal.best_params_)\n",
    "\n",
    "grid_3_res_normal.fit(X_train_res, y_train_res)\n",
    "print(grid_3_res_normal.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models_res = []\n",
    "models_res.append(('SVM rbf', grid_1_res_normal.best_estimator_))\n",
    "models_res.append(('LogReg', grid_2_res_normal.best_estimator_))\n",
    "models_res.append(('RND', grid_3_res_normal.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models_res_chosen:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1_res_normal.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2_res_normal.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3_res_normal.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid3 --> Resampling normalnie I-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_post</th>\n",
       "      <th>... per Post</th>\n",
       "      <th>http per Post</th>\n",
       "      <th>music per Post</th>\n",
       "      <th>jpg per Post</th>\n",
       "      <th>I per Post</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>21.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
       "      <td>29.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
       "      <td>26.58</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "      <td>24.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>I'm not sure, that's a good question. The dist...</td>\n",
       "      <td>14.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
       "      <td>24.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  words_per_post  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           11.12   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...           23.40   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...           16.72   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...           21.28   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...           19.34   \n",
       "5  INTJ  '18/37 @.@|||Science  is not perfect. No scien...           29.82   \n",
       "6  INFJ  'No, I can't draw on my own nails (haha). Thos...           26.58   \n",
       "7  INTJ  'I tend to build up a collection of things on ...           24.46   \n",
       "8  INFJ  I'm not sure, that's a good question. The dist...           14.76   \n",
       "9  INTP  'https://www.youtube.com/watch?v=w8-egj0y8Qs||...           24.66   \n",
       "\n",
       "   ... per Post  http per Post  music per Post  jpg per Post  I per Post  I-E  \\\n",
       "0          0.30           0.48            0.02          0.12        0.46    0   \n",
       "1          0.38           0.20            0.00          0.02        2.02    1   \n",
       "2          0.26           0.10            0.00          0.00        0.98    0   \n",
       "3          0.52           0.04            0.02          0.00        1.74    0   \n",
       "4          0.42           0.12            0.02          0.04        0.92    1   \n",
       "5          0.78           0.02            0.00          0.00        1.88    0   \n",
       "6          0.74           0.04            0.02          0.00        1.88    0   \n",
       "7          0.56           0.02            0.04          0.00        0.32    0   \n",
       "8          0.34           0.46            0.02          0.02        0.98    0   \n",
       "9          0.48           0.14            0.02          0.00        0.20    0   \n",
       "\n",
       "   N-S  T-F  J-P  \n",
       "0    0    1    0  \n",
       "1    0    0    1  \n",
       "2    0    0    1  \n",
       "3    0    0    0  \n",
       "4    0    0    0  \n",
       "5    0    0    0  \n",
       "6    0    1    0  \n",
       "7    0    0    0  \n",
       "8    0    1    0  \n",
       "9    0    0    1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map1 = {\"I\": 0, \"E\": 1}\n",
    "map2 = {\"N\": 0, \"S\": 1}\n",
    "map3 = {\"T\": 0, \"F\": 1}\n",
    "map4 = {\"J\": 0, \"P\": 1}\n",
    "df['I-E'] = df['type'].astype(str).str[0]\n",
    "df['I-E'] = df['I-E'].map(map1)\n",
    "df['N-S'] = df['type'].astype(str).str[1]\n",
    "df['N-S'] = df['N-S'].map(map2)\n",
    "df['T-F'] = df['type'].astype(str).str[2]\n",
    "df['T-F'] = df['T-F'].map(map3)\n",
    "df['J-P'] = df['type'].astype(str).str[3]\n",
    "df['J-P'] = df['J-P'].map(map4)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7e44b6ff2e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "XX = df.drop(['type','posts','I-E','N-S','T-F','J-P'], axis=1).values\n",
    "yy = df['I-E'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1_res_normal_IE = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2_res_normal_IE = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3_res_normal_IE = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1_res_normal_IE.fit(X_train_res, y_train_res)\n",
    "print(grid_1_res_normal_IE .best_params_)\n",
    "\n",
    "grid_2_res_normal_IE.fit(X_train_res, y_train_res)\n",
    "print(grid_2_res_normal_IE .best_params_)\n",
    "\n",
    "grid_3_res_normal_IE.fit(X_train_res, y_train_res)\n",
    "print(grid_3_res_normal_IE .best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models_res = []\n",
    "models_res.append(('SVM rbf', grid_1_res_normal_IE.best_estimator_))\n",
    "models_res.append(('LogReg', grid_2_res_normal_IE.best_estimator_))\n",
    "models_res.append(('RND', grid_3_res_normal_IE.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models_res_chosen:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1_res_normal_IE.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2_res_normal_IE.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3_res_normal_IE.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "XX = df.drop(['type','posts','I-E','N-S','T-F','J-P'], axis=1).values\n",
    "yy = df['N-S'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1_res_normal_NS = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2_res_normal_NS = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3_res_normal_NS = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1_res_normal_NS.fit(X_train_res, y_train_res)\n",
    "print(grid_1_res_normal_NS.best_params_)\n",
    "\n",
    "grid_2_res_normal_NS.fit(X_train_res, y_train_res)\n",
    "print(grid_2_res_normal_NS.best_params_)\n",
    "\n",
    "grid_3_res_normal_IE.fit(X_train_res, y_train_res)\n",
    "print(grid_3_res_normal_NS.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models_res = []\n",
    "models_res.append(('SVM rbf', grid_1_res_normal_NS.best_estimator_))\n",
    "models_res.append(('LogReg', grid_2_res_normal_NS.best_estimator_))\n",
    "models_res.append(('RND', grid_3_res_normal_NS.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models_res_chosen:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1_res_normal_NS.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2_res_normal_NS.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3_res_normal_NS.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "XX = df.drop(['type','posts','I-E','N-S','T-F','J-P'], axis=1).values\n",
    "yy = df['T-F'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1_res_normal_TF = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2_res_normal_TF = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3_res_normal_TF = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1_res_normal_TF.fit(X_train_res, y_train_res)\n",
    "print(grid_1_res_normal_TF.best_params_)\n",
    "\n",
    "grid_2_res_normal_TF.fit(X_train_res, y_train_res)\n",
    "print(grid_2_res_normal_TF.best_params_)\n",
    "\n",
    "grid_3_res_normal_TF.fit(X_train_res, y_train_res)\n",
    "print(grid_3_res_normal_TF.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models_res = []\n",
    "models_res.append(('SVM rbf', grid_1_res_normal_TF.best_estimator_))\n",
    "models_res.append(('LogReg', grid_2_res_normal_TF.best_estimator_))\n",
    "models_res.append(('RND', grid_3_res_normal_TF.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models_res_chosen:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1_res_normal_TF.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2_res_normal_TF.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3_res_normal_TF.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "XX = df.drop(['type','posts','I-E','N-S','T-F','J-P'], axis=1).values\n",
    "yy = df['J-P'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1_res_normal_JP = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2_res_normal_JP = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3_res_normal_JP = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1_res_normal_JP.fit(X_train_res, y_train_res)\n",
    "print(grid_1_res_normal_JP.best_params_)\n",
    "\n",
    "grid_2_res_normal_JP.fit(X_train_res, y_train_res)\n",
    "print(grid_2_res_normal_JP.best_params_)\n",
    "\n",
    "grid_3_res_normal_JP.fit(X_train_res, y_train_res)\n",
    "print(grid_3_res_normal_JP.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models_res = []\n",
    "models_res.append(('SVM rbf', grid_1_res_normal_JP.best_estimator_))\n",
    "models_res.append(('LogReg', grid_2_res_normal_JP.best_estimator_))\n",
    "models_res.append(('RND', grid_3_res_normal_JP.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models_res_chosen:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1_res_normal_JP.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2_res_normal_JP.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3_res_normal_JP.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selekcja Automatyczna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    return text\n",
    "df['clean_posts'] = df['posts'].apply(cleanText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Czyścimy zbiór Danych z  niepotrzebnych linków itp.\n",
    "\n",
    "XX = df['clean_posts'].values\n",
    "yy = df['type'].values\n",
    "\n",
    "print(XX.shape)\n",
    "print(yy.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(XX,yy,test_size = 0.1, random_state=42)\n",
    "\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "\n",
    "#Przeprowadzamy Text Mining oraz Skalowanie danych i redukcje wymiarów\n",
    "\n",
    "TfidVect  = tfidf.fit_transform(X_train_res)\n",
    "svd_model = tsvd\n",
    "data_revitalised = svd_model.fit_transform(TfidVect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "param_grid2 = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['none','l2']}\n",
    "param_grid3 = {'max_leaf_nodes': [10, 16, 32, 64, 80]}\n",
    "\n",
    "param_grid4 = {'n_estimators': [100,200,300,400,500,600,700,800,900,1000],'max_leaf_nodes' : [2,48,16,32,64]}\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_1_res_Automatic = GridSearchCV(SVC(kernel = 'rbf',probability=True), param_grid, cv=kfold, return_train_score=True)\n",
    "grid_2_res_Automatic = GridSearchCV(LogisticRegression(), param_grid2, cv=kfold, return_train_score=True)\n",
    "grid_3_res_Automatic = GridSearchCV(ExtraTreesClassifier(), param_grid4, cv=kfold, return_train_score=True)\n",
    "\n",
    "\n",
    "grid_1_res_Automatic.fit(data_revitalised, y_train_res)\n",
    "print(grid_1_res_Automatic.best_params_)\n",
    "\n",
    "grid_2_res_Automatic.fit(data_revitalised, y_train_res)\n",
    "print(grid_2_res_Automatic.best_params_)\n",
    "\n",
    "grid_3_res_Automatic.fit(data_revitalised, y_train_res)\n",
    "print(grid_3_res_Automatic.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pokazujemy Dokładność Modelu\n",
    "\n",
    "\n",
    "from sklearn import  metrics\n",
    "\n",
    "models_res = []\n",
    "models_res.append(('SVM rbf', grid_1_res_Automatic.best_estimator_))\n",
    "models_res.append(('LogReg', grid_2_res_Automatic.best_estimator_))\n",
    "models_res.append(('RND', grid_3_res_Automatic.best_estimator_))\n",
    "\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models_res_chosen:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.precision_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test),average='micro') ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test),average='micro'))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test),average='micro'))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test),average='micro'))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array =metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    personality_types = np.unique(y_test)\n",
    "\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in personality_types],\n",
    "                      columns = [i for i in personality_types])\n",
    "\n",
    "    plt.figure(figsize = (15,15))\n",
    "    heatmap(array, xlabel='True', xticklabels=personality_types, ylabel='Predicted', yticklabels=personality_types, cmap=\"plasma\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM\")\n",
    "results1 = pd.DataFrame(grid_1_res_Automatic.cv_results_)\n",
    "\n",
    "scores1 = np.array(results1.mean_test_score).reshape(6, 6)\n",
    "\n",
    "heatmap(scores1, xlabel='gamma', xticklabels=param_grid['gamma'], ylabel='C', yticklabels=param_grid['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"LogReg\")\n",
    "\n",
    "results2 = pd.DataFrame(grid_2_res_Automatic.cv_results_)\n",
    "\n",
    "scores2 = np.array(results2.mean_test_score).reshape(6, 2)\n",
    "\n",
    "heatmap(scores2, xlabel='gamma', xticklabels=param_grid2['penalty'], ylabel='C', yticklabels=param_grid2['C'], cmap=\"plasma\")\n",
    "plt.show()\n",
    "print(\"ETC\")\n",
    "\n",
    "results3 = pd.DataFrame(grid_3_res_Automatic.cv_results_)\n",
    "\n",
    "scores3 = np.array(results3.mean_test_score).reshape(5, 10)\n",
    "\n",
    "heatmap(scores3, xlabel='n_estimators', xticklabels=param_grid4['n_estimators'], ylabel='max_leaf_nodes', yticklabels=param_grid4['max_leaf_nodes'], cmap=\"plasma\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
